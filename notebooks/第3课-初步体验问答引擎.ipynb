{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "# 从环境变量中读取api_key\n",
    "api_key = os.getenv('ZHIPU_API_KEY')\n",
    "base_url = \"https://open.bigmodel.cn/api/paas/v4/\"\n",
    "chat_model = \"glm-4-flash\"\n",
    "emb_model = \"embedding-2\"\n",
    "\n",
    "# 配置对话模型\n",
    "from llama_index.llms.zhipuai import ZhipuAI\n",
    "llm = ZhipuAI(\n",
    "    api_key = api_key,\n",
    "    model = chat_model,\n",
    ")\n",
    "\n",
    "# 配置嵌入模型\n",
    "from llama_index.embeddings.zhipuai import ZhipuAIEmbedding\n",
    "embedding = ZhipuAIEmbedding(\n",
    "    api_key = api_key,\n",
    "    model = emb_model,\n",
    ")\n",
    "emb = embedding.get_text_embedding(\"你好呀呀\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "做RAG需要自己准备一个txt文档，新建一个docs文件夹，放进去。例如，这里放了一个./docs/问答手册.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从指定文件读取，输入为List\n",
    "from llama_index.core import SimpleDirectoryReader,Document\n",
    "documents = SimpleDirectoryReader(input_files=['./docs/问答手册.txt']).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法一：Documents可以直接构建index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建向量索引\n",
    "from llama_index.core import VectorStoreIndex\n",
    "index = VectorStoreIndex.from_documents(documents,embed_model=embedding)\n",
    "# 想要看到进度条的话，加一个参数 show_progress=True\n",
    "# index = VectorStoreIndex.from_documents(documents,embed_model=embedding,show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法二：可以先构建节点，再构建索引，同时采用faiss作为向量存储库\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建节点\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "transformations = [SentenceSplitter(chunk_size = 512)]\n",
    "\n",
    "from llama_index.core.ingestion.pipeline import run_transformations\n",
    "nodes = run_transformations(documents, transformations=transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据节点构建索引\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建索引\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "import faiss\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "\n",
    "# 从上一节得知，智谱embedding-2的维度是1024\n",
    "dimensions = len(emb)\n",
    "vector_store = FaissVectorStore(faiss_index=faiss.IndexFlatL2(dimensions))\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex(\n",
    "    nodes = nodes,\n",
    "    storage_context=storage_context,\n",
    "    embed_model = embedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样索引就算是建成了。我们可以把索引存储到硬盘，这样以后就不用重复构建，直接从硬盘读取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save index to disk\n",
    "persist_dir = \"./storage\"\n",
    "index.storage_context.persist(persist_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果之前有保存过索引到硬盘，可以直接读取。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index from disk\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "import faiss\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "vector_store = FaissVectorStore.from_persist_dir(persist_dir)\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store, persist_dir=persist_dir\n",
    ")\n",
    "index = load_index_from_storage(storage_context=storage_context,embed_model = embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index可以直接做问答引擎。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='专利申请的收费通常包括官方费用和代理费用两部分。官方费用包括申请费、审查费、授权费等，具体收费标准由各国专利局规定，不同国家可能有所不同。代理费用则由专利代理机构或代理人根据服务内容、工作量等因素自行定价。在提交专利申请时，建议咨询专业的专利代理机构以获取详细费用信息。', source_nodes=[NodeWithScore(node=TextNode(id_='648f86a2-27a1-45a3-b59b-79723b76b3e0', embedding=None, metadata={'file_path': 'docs/问答手册.txt', 'file_name': '问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2025-03-20', 'last_modified_date': '2025-03-20'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='225df03b-8a2f-48c8-88c5-ba8239dca542', node_type='4', metadata={'file_path': 'docs/问答手册.txt', 'file_name': '问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2025-03-20', 'last_modified_date': '2025-03-20'}, hash='11aa24379c93cca29d0797f16e428d606adf5ecd542e488a07a29e676e324306'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='130bfcbe-716e-4256-8fee-4e3e1cbf4dd6', node_type='1', metadata={'file_path': 'docs/问答手册.txt', 'file_name': '问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2025-03-20', 'last_modified_date': '2025-03-20'}, hash='c55f88276a75a5cf7a714aaf1baba103b2249006daf8f3865a60b7aec84942eb')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='2) In the gaming industry, AI agents could transform the role of developers, shifting their focus from scripting non-player characters to refining agent learning processes. Similarly, adaptive robotic systems could redefine manufacturing roles, necessitating new skill sets rather than replacing human workers. Navigating these transitions responsibly is vital to minimize potential socio-economic disruptions.\\r\\n\\r\\nFurthermore, the agent AI focuses on learning collaboration policy in simulation and there is some risk if directly applying the policy to the real world due to the distribution shift. Robust testing and continual safety monitoring mechanisms should be put in place to minimize risks of unpredictable behaviors in real-world scenarios. Our “VideoAnalytica\" dataset is collected from the Internet and considering which is not a fully representative source, so we already go through-ed the ethical review and legal process from both Microsoft and University Washington. Be that as it may, we also need to understand biases that might exist in this corpus. Data distributions can be characterized in many ways. In this workshop, we have captured how the agent level distribution in our dataset is different from other existing datasets. However, there is much more than could be included in a single dataset or workshop. We would argue that there is a need for more approaches or discussion linked to real tasks or topics and that by making these data or system available.\\r\\n\\r\\nWe will dedicate a segment of our project to discussing these ethical issues, exploring potential mitigation strategies, and deploying a responsible multi-modal AI agent. We hope to help more researchers answer these questions together via this paper.', mimetype='text/plain', start_char_idx=1615, end_char_idx=3353, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=1.627665638923645), NodeWithScore(node=TextNode(id_='130bfcbe-716e-4256-8fee-4e3e1cbf4dd6', embedding=None, metadata={'file_path': 'docs/问答手册.txt', 'file_name': '问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2025-03-20', 'last_modified_date': '2025-03-20'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='225df03b-8a2f-48c8-88c5-ba8239dca542', node_type='4', metadata={'file_path': 'docs/问答手册.txt', 'file_name': '问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2025-03-20', 'last_modified_date': '2025-03-20'}, hash='11aa24379c93cca29d0797f16e428d606adf5ecd542e488a07a29e676e324306'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='648f86a2-27a1-45a3-b59b-79723b76b3e0', node_type='1', metadata={}, hash='5128f538caf583931f5dcc7bd0d013dd356a78f5eaf21fb9dae1dba236603900')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Multimodal Agent AI systems have many applications. In addition to interactive AI, grounded multimodal models could help drive content generation for bots and AI agents, and assist in productivity applications, helping to re-play, paraphrase, action prediction or synthesize 3D or 2D scenario. Fundamental advances in agent AI help contribute towards these goals and many would benefit from a greater understanding of how to model embodied and empathetic in a simulate reality or a real world. Arguably many of these applications could have positive benefits.\\r\\n\\r\\nHowever, this technology could also be used by bad actors. Agent AI systems that generate content can be used to manipulate or deceive people. Therefore, it is very important that this technology is developed in accordance with responsible AI guidelines. For example, explicitly communicating to users that content is generated by an AI system and providing the user with controls in order to customize such a system. It is possible the Agent AI could be used to develop new methods to detect manipulative content - partly because it is rich with hallucination performance of large foundation model - and thus help address another real world problem.\\r\\n\\r\\nFor examples, 1) in health topic, ethical deployment of LLM and VLM agents, especially in sensitive domains like healthcare, is paramount. AI agents trained on biased data could potentially worsen health disparities by providing inaccurate diagnoses for underrepresented groups. Moreover, the handling of sensitive patient data by AI agents raises significant privacy and confidentiality concerns. 2) In the gaming industry, AI agents could transform the role of developers, shifting their focus from scripting non-player characters to refining agent learning processes. Similarly, adaptive robotic systems could redefine manufacturing roles, necessitating new skill sets rather than replacing human workers. Navigating these transitions responsibly is vital to minimize potential socio-economic disruptions.\\r\\n\\r\\nFurthermore, the agent AI focuses on learning collaboration policy in simulation and there is some risk if directly applying the policy to the real world due to the distribution shift. Robust testing and continual safety monitoring mechanisms should be put in place to minimize risks of unpredictable behaviors in real-world scenarios. Our “VideoAnalytica\" dataset is collected from the Internet and considering which is not a fully representative source, so we already go through-ed the ethical review and legal process from both Microsoft and University Washington. Be that as it may, we also need to understand biases that might exist in this corpus. Data distributions can be characterized in many ways.', mimetype='text/plain', start_char_idx=0, end_char_idx=2736, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=1.8256853818893433)], metadata={'648f86a2-27a1-45a3-b59b-79723b76b3e0': {'file_path': 'docs/问答手册.txt', 'file_name': '问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2025-03-20', 'last_modified_date': '2025-03-20'}, '130bfcbe-716e-4256-8fee-4e3e1cbf4dd6': {'file_path': 'docs/问答手册.txt', 'file_name': '问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2025-03-20', 'last_modified_date': '2025-03-20'}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(llm=llm)\n",
    "# 回答提问\n",
    "response = query_engine.query(\"专利申请如何收费？\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "response.text 中是回答的文本。response.source_nodes是检索到的文本块儿，每个文本块都有score，代表与问题的相关性，由向量计算得出。\n",
    "\n",
    "方法三：我们也可以先构建索引器，再构建合成器，再组装成问答引擎。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建检索器\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "# 想要自定义参数，可以构造参数字典\n",
    "kwargs = {'similarity_top_k': 5, 'index': index, 'dimensions': dimensions} # 必要参数\n",
    "retriever = VectorIndexRetriever(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建合成器\n",
    "from llama_index.core.response_synthesizers  import get_response_synthesizer\n",
    "response_synthesizer = get_response_synthesizer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建问答引擎\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "engine = RetrieverQueryEngine(\n",
    "      retriever=retriever,\n",
    "      response_synthesizer=response_synthesizer\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "商标注册通常需要提交以下文件：\n",
      "\n",
      "1. 商标注册申请书：详细填写商标的名称、使用商品或服务类别、申请人名称、地址等信息。\n",
      "\n",
      "2. 商标图样：提供清晰的商标图样，应保证颜色、形状、比例等与实际使用一致。\n",
      "\n",
      "3. 申请人身份证明文件：个人申请需提供身份证复印件，企业申请需提供营业执照副本复印件。\n",
      "\n",
      "4. 使用证明文件：若商标已在市场中使用，需提交相应的使用证明文件，如销售合同、广告宣传资料等。\n",
      "\n",
      "5. 商标代理委托书：如申请人委托代理人办理商标注册事宜，需提供委托书。\n",
      "\n",
      "6. 其他证明文件：根据具体情况，可能还需提交其他证明文件，如商品或服务分类的相关证明、商标设计说明等。\n",
      "\n",
      "请注意，不同国家和地区的商标注册要求和文件可能有所不同，具体请咨询当地商标局或专业机构。\n"
     ]
    }
   ],
   "source": [
    "# 提问\n",
    "question = \"请问商标注册需要提供哪些文件？\"\n",
    "answer = engine.query(question)\n",
    "print(answer.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在商标注册中，对于企业来说，需要提供的文件包括：\n",
    "- 被申请人提供的营业执照复印件；\n",
    "- 授权委托书；\n",
    "- 商标图案的电子版；\n",
    "- 具体商品或服务的名称。\n",
    "\n",
    "若是国内自然人申请商标，则需提供以下文件：\n",
    "- 个体工商户档案及自然人身份证复印件；\n",
    "- 授权委托书；\n",
    "- 商标图案的电子版；\n",
    "- 具体商品或服务的名称。\n",
    "\n",
    "国外自然人则需要提供：\n",
    "- 护照；\n",
    "- 授权委托书；\n",
    "- 及商标图案的电子版；\n",
    "- 具体商品或服务的名称。\n",
    "\n",
    "### 方法四：利用Qdrant向量库\n",
    "\n",
    "先安装一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting qdrant-client\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/dd/b4/bd676f91f5234ab59282e4a110f324029684482cbe08e7a1c77b6338013b/qdrant_client-1.13.3-py3-none-any.whl (306 kB)\n",
      "Collecting grpcio>=1.41.0 (from qdrant-client)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/5d/b7/7e7b7bb6bb18baf156fd4f2f5b254150dcdd6cbf0def1ee427a2fb2bfc4d/grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio-tools>=1.41.0 (from qdrant-client)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/e3/4b/d95be4aaf78d7b02dff3bd332c75c228288178e92af0e5228759ac5002a0/grpcio_tools-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: httpx>=0.20.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.21 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from qdrant-client) (1.26.4)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/9b/fb/a70a4214956182e0d7a9099ab17d50bfcba1056188e9b14f35b9e2b62a0d/portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from qdrant-client) (2.10.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from qdrant-client) (2.3.0)\n",
      "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-tools>=1.41.0->qdrant-client)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/a8/45/2ebbde52ad2be18d3675b6bee50e68cd73c9e0654de77d595540b5129df8/protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Requirement already satisfied: setuptools in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from grpcio-tools>=1.41.0->qdrant-client) (75.8.0)\n",
      "Requirement already satisfied: anyio in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.14.0)\n",
      "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/d0/9e/984486f2d0a0bd2b024bf4bc1c62688fcafa9e61991f041fb0e2def4a982/h2-4.2.0-py3-none-any.whl (60 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from pydantic>=1.10.8->qdrant-client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from pydantic>=1.10.8->qdrant-client) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from pydantic>=1.10.8->qdrant-client) (4.12.2)\n",
      "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/48/30/47d0bf6072f7252e6521f3447ccfa40b421b6824517f82854703d0f5a98b/hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/07/c6/80c95b1b2b94682a72cbdbfb85b81ae2daffa4291fbfa1b1464502ede10d/hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
      "Installing collected packages: protobuf, portalocker, hyperframe, hpack, grpcio, h2, grpcio-tools, qdrant-client\n",
      "Successfully installed grpcio-1.71.0 grpcio-tools-1.71.0 h2-4.2.0 hpack-4.1.0 hyperframe-6.1.0 portalocker-2.10.1 protobuf-5.29.3 qdrant-client-1.13.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting llama-index-vector-stores-qdrant\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/ff/30/d8ab459dd582dbfa3c7e101364c0b6d2d51f42063d0e03fb1b2d6a486c6b/llama_index_vector_stores_qdrant-0.5.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.60.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-vector-stores-qdrant) (1.71.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.7 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-vector-stores-qdrant) (0.12.25)\n",
      "Requirement already satisfied: qdrant-client>=1.7.1 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-vector-stores-qdrant) (1.13.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (2.0.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (3.11.14)\n",
      "Requirement already satisfied: dataclasses-json in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (2025.3.0)\n",
      "Requirement already satisfied: httpx in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (3.9.1)\n",
      "Requirement already satisfied: numpy in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.17.2)\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from qdrant-client>=1.7.1->llama-index-vector-stores-qdrant) (1.71.0)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from qdrant-client>=1.7.1->llama-index-vector-stores-qdrant) (2.10.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from qdrant-client>=1.7.1->llama-index-vector-stores-qdrant) (2.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.18.3)\n",
      "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from grpcio-tools>=1.41.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant) (5.29.3)\n",
      "Requirement already satisfied: setuptools in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from grpcio-tools>=1.41.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant) (75.8.0)\n",
      "Requirement already satisfied: anyio in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant) (4.2.0)\n",
      "Requirement already satisfied: click in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (3.4.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (3.26.1)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant) (4.1.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (24.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.3.1)\n",
      "Installing collected packages: llama-index-vector-stores-qdrant\n",
      "Successfully installed llama-index-vector-stores-qdrant-0.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: llama-index-readers-file in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (0.4.6)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-readers-file) (4.13.3)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-readers-file) (0.12.25)\n",
      "Requirement already satisfied: pandas in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-readers-file) (2.2.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-readers-file) (5.4.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-readers-file) (0.0.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.0.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.11.14)\n",
      "Requirement already satisfied: dataclasses-json in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2025.3.0)\n",
      "Requirement already satisfied: httpx in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.9.1)\n",
      "Requirement already satisfied: numpy in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (4.67.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.17.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from pandas->llama-index-readers-file) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from pandas->llama-index-readers-file) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from pandas->llama-index-readers-file) (2025.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.18.3)\n",
      "Requirement already satisfied: click in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.26.1)\n",
      "Requirement already satisfied: anyio in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (24.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install qdrant-client\n",
    "%pip install llama-index-vector-stores-qdrant\n",
    "%pip install llama-index-readers-file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载文档\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: 4b587f56-90a3-45d9-9d87-a4282fe32a7c\n"
     ]
    }
   ],
   "source": [
    "import qdrant_client\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=['./docs/问答手册.txt']\n",
    ").load_data()\n",
    "\n",
    "print(\"Document ID:\", documents[0].doc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document ID: 02572b3e-18f7-4b5e-b432-3e1ed9ba89b8\n",
    "\n",
    "构建索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages/llama_index/vector_stores/qdrant/base.py:703: UserWarning: Payload indexes have no effect in the local Qdrant. Please use server Qdrant if you need payload indexes.\n",
      "  self._client.create_payload_index(\n"
     ]
    }
   ],
   "source": [
    "# Create an index over the documents\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "\n",
    "# 连接Qdrant，并保存在本地的qdrant文件夹中\n",
    "qclient = qdrant_client.QdrantClient(path=\"qdrant\")\n",
    "vector_store = QdrantVectorStore(client=qclient, collection_name=\"wenda\")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, \n",
    "    storage_context=storage_context,\n",
    "    embed_model = embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建检索器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建检索器\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "# 想要自定义参数，可以构造参数字典\n",
    "kwargs = {'similarity_top_k': 5, 'index': index, 'dimensions': dimensions} # 必要参数\n",
    "retriever = VectorIndexRetriever(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建合成器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建合成器\n",
    "from llama_index.core.response_synthesizers  import get_response_synthesizer\n",
    "response_synthesizer = get_response_synthesizer(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建问答引擎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建问答引擎\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "engine = RetrieverQueryEngine(\n",
    "      retriever=retriever,\n",
    "      response_synthesizer=response_synthesizer,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent AI systems have applications across various domains, including driving content generation for bots and AI agents, enhancing productivity in scenarios like re-playing, paraphrasing, action prediction, and synthesizing 3D or 2D scenarios. They also contribute to interactive AI, health topic management, transforming the gaming industry by redefining developer roles, and reshaping manufacturing through adaptive robotic systems.\n"
     ]
    }
   ],
   "source": [
    "# 提问\n",
    "question = \"What are the applications of Agent AI systems ?\"\n",
    "answer = engine.query(question)\n",
    "print(answer.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent AI systems have a variety of applications, which include:\n",
    "\n",
    "1. Interactive AI: Enhancing user interactions and providing personalized experiences.\n",
    "2. Content Generation: Assisting in the creation of content for bots and AI agents, which can be used in various applications such as customer service or storytelling.\n",
    "3. Productivity: Improving productivity in applications by enabling tasks like replaying events, paraphrasing information, predicting actions, and synthesizing scenarios (both 3D and 2D).\n",
    "4. Healthcare: Ethical deployment in sensitive domains like healthcare, which could potentially improve diagnoses and patient care while also addressing health disparities.\n",
    "5. Gaming Industry: Transforming the role of developers by shifting focus from scripting non-player characters to refining agent learning processes.\n",
    "6. Robotics and Manufacturing: Redefining manufacturing roles and requiring new skill sets, rather than replacing human workers, as adaptive robotic systems are developed.\n",
    "7. Simulation: Learning collaboration policies within simulated environments, which can be applied to the real world with careful consideration and safety measures.\n",
    "\n",
    "Qdrant是支持metadata filter的，我们可以在构建索引的时候，给每个文档添加metadata，然后在查询的时候，指定metadata filter。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "nodes = [\n",
    "    TextNode(\n",
    "        text=\"The Shawshank Redemption\",\n",
    "        metadata={\n",
    "            \"author\": \"Stephen King\",\n",
    "            \"theme\": \"Friendship\",\n",
    "            \"year\": 1994,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"The Godfather\",\n",
    "        metadata={\n",
    "            \"director\": \"Francis Ford Coppola\",\n",
    "            \"theme\": \"Mafia\",\n",
    "            \"year\": 1972,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"Inception\",\n",
    "        metadata={\n",
    "            \"director\": \"Christopher Nolan\",\n",
    "            \"theme\": \"Fiction\",\n",
    "            \"year\": 2010,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"To Kill a Mockingbird\",\n",
    "        metadata={\n",
    "            \"author\": \"Harper Lee\",\n",
    "            \"theme\": \"Mafia\",\n",
    "            \"year\": 1960,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"1984\",\n",
    "        metadata={\n",
    "            \"author\": \"George Orwell\",\n",
    "            \"theme\": \"Totalitarianism\",\n",
    "            \"year\": 1949,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"The Great Gatsby\",\n",
    "        metadata={\n",
    "            \"author\": \"F. Scott Fitzgerald\",\n",
    "            \"theme\": \"The American Dream\",\n",
    "            \"year\": 1925,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"Harry Potter and the Sorcerer's Stone\",\n",
    "        metadata={\n",
    "            \"author\": \"J.K. Rowling\",\n",
    "            \"theme\": \"Fiction\",\n",
    "            \"year\": 1997,\n",
    "        },\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据上面的nodes，构建索引。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = QdrantVectorStore(client=qclient, collection_name=\"filter\")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex(\n",
    "    nodes, \n",
    "    storage_context=storage_context,\n",
    "    embed_model = embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们就可以构建metadata filter了。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import (\n",
    "    MetadataFilter,\n",
    "    MetadataFilters,\n",
    "    FilterOperator,\n",
    ")\n",
    "\n",
    "filters = MetadataFilters(\n",
    "    filters=[\n",
    "        MetadataFilter(key=\"theme\", operator=FilterOperator.EQ, value=\"Mafia\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把构建好的filter当作参数，构建retriever。进行检索，查看一下结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='c0b9055d-7317-4f99-8392-b4fe3fdd762d', embedding=None, metadata={'director': 'Francis Ford Coppola', 'theme': 'Mafia', 'year': 1972}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='The Godfather', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.27578755699862606),\n",
       " NodeWithScore(node=TextNode(id_='7316d5ec-53ff-467d-9187-78ccc6c8ec5b', embedding=None, metadata={'author': 'Harper Lee', 'theme': 'Mafia', 'year': 1960}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='To Kill a Mockingbird', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.24003890332847805)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = index.as_retriever(filters=filters, llm=llm)\n",
    "retriever.retrieve(\"What is inception about?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NodeWithScore(node=TextNode(id_='37eb454b-8626-4907-b19d-0c693e8cdab3', embedding=None, metadata={'director': 'Francis Ford Coppola', 'theme': 'Mafia', 'year': 1972}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='The Godfather', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.43338348085207457),\n",
    " NodeWithScore(node=TextNode(id_='0d33fe2e-d511-400d-a314-5dab62911afc', embedding=None, metadata={'author': 'Harper Lee', 'theme': 'Mafia', 'year': 1960}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='To Kill a Mockingbird', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.4314900148435552)]\n",
    "\n",
    "\n",
    "我们还可以用AND或者OR来组合多个filter。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='2d2d90bf-bbd2-45ea-a974-d3638d4e2384', embedding=None, metadata={'director': 'Christopher Nolan', 'theme': 'Fiction', 'year': 2010}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Inception', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.27688714316899976)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " from llama_index.core.vector_stores import FilterOperator, FilterCondition\n",
    "\n",
    "filters = MetadataFilters(\n",
    "    filters=[\n",
    "        MetadataFilter(key=\"theme\", value=\"Fiction\"),\n",
    "        MetadataFilter(key=\"year\", value=1997, operator=FilterOperator.GT),\n",
    "    ],\n",
    "    condition=FilterCondition.AND,\n",
    ")\n",
    "\n",
    "retriever = index.as_retriever(filters=filters, llm=llm)\n",
    "retriever.retrieve(\"Harry Potter?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NodeWithScore(node=TextNode(id_='62204c33-04de-4d4a-b311-41ed54d9ba27', embedding=None, metadata={'director': 'Christopher Nolan', 'theme': 'Fiction', 'year': 2010}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Inception', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.250045814238684)]\n",
    "\n",
    "我们也可以直接把filter的字典作为参数，构建retriever。这样可以构建一个更复杂的filter。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='2d2d90bf-bbd2-45ea-a974-d3638d4e2384', embedding=None, metadata={'director': 'Christopher Nolan', 'theme': 'Fiction', 'year': 2010}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Inception', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.6196639144997296),\n",
       " NodeWithScore(node=TextNode(id_='25367f9d-81d4-4a78-846c-46a5b9a8e927', embedding=None, metadata={'author': 'George Orwell', 'theme': 'Totalitarianism', 'year': 1949}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='1984', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.348853014289105)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = index.as_retriever(\n",
    "    vector_store_kwargs={\"filter\": {\"theme\": \"Mafia\"}},\n",
    "    llm=llm\n",
    ")\n",
    "retriever.retrieve(\"What is inception about?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NodeWithScore(node=TextNode(id_='a681947d-5d5e-43c6-89ba-25bfae2fb882', embedding=None, metadata={'author': 'Stephen King', 'theme': 'Friendship', 'year': 1994}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='The Shawshank Redemption', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.4834685059141362),\n",
    " NodeWithScore(node=TextNode(id_='37eb454b-8626-4907-b19d-0c693e8cdab3', embedding=None, metadata={'director': 'Francis Ford Coppola', 'theme': 'Mafia', 'year': 1972}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='The Godfather', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.43338348085207457)]\n",
    "\n",
    "\n",
    "除了llama-index提供的检索方式，我们还可以利用Qdrant自带的检索能力。就是Default Qdrant Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [\n",
    "    TextNode(\n",
    "        text=\"りんごとは\",\n",
    "        metadata={\"author\": \"Tanaka\", \"fruit\": \"apple\", \"city\": \"Tokyo\"},\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"Was ist Apfel?\",\n",
    "        metadata={\"author\": \"David\", \"fruit\": \"apple\", \"city\": \"Berlin\"},\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"Orange like the sun\",\n",
    "        metadata={\"author\": \"Jane\", \"fruit\": \"orange\", \"city\": \"Hong Kong\"},\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"Grape is...\",\n",
    "        metadata={\"author\": \"Jane\", \"fruit\": \"grape\", \"city\": \"Hong Kong\"},\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"T-dot > G-dot\",\n",
    "        metadata={\"author\": \"George\", \"fruit\": \"grape\", \"city\": \"Toronto\"},\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"6ix Watermelons\",\n",
    "        metadata={\n",
    "            \"author\": \"George\",\n",
    "            \"fruit\": \"watermelon\",\n",
    "            \"city\": \"Toronto\",\n",
    "        },\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "继续构建向量库。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = QdrantVectorStore(client=qclient, collection_name=\"default\")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex(\n",
    "    nodes, \n",
    "    storage_context=storage_context,\n",
    "    embed_model = embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建Qdrant自己的的filter。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http.models import Filter, FieldCondition, MatchValue\n",
    "filters = Filter(\n",
    "    should=[\n",
    "        Filter(\n",
    "            must=[\n",
    "                FieldCondition(\n",
    "                    key=\"fruit\",\n",
    "                    match=MatchValue(value=\"apple\"),\n",
    "                ),\n",
    "                FieldCondition(\n",
    "                    key=\"city\",\n",
    "                    match=MatchValue(value=\"Tokyo\"),\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        Filter(\n",
    "            must=[\n",
    "                FieldCondition(\n",
    "                    key=\"fruit\",\n",
    "                    match=MatchValue(value=\"grape\"),\n",
    "                ),\n",
    "                FieldCondition(\n",
    "                    key=\"city\",\n",
    "                    match=MatchValue(value=\"Toronto\"),\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建retriever。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(\n",
    "    vector_store_kwargs={\"qdrant_filters\": filters},\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检索一下看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node 0.3977733458258037\n",
      "node T-dot > G-dot\n",
      "node {'author': 'George', 'fruit': 'grape', 'city': 'Toronto'}\n",
      "node 0.2929864224097565\n",
      "node りんごとは\n",
      "node {'author': 'Tanaka', 'fruit': 'apple', 'city': 'Tokyo'}\n"
     ]
    }
   ],
   "source": [
    "response = retriever.retrieve(\"Who makes grapes?\")\n",
    "for node in response:\n",
    "    print(\"node\", node.score)\n",
    "    print(\"node\", node.text)\n",
    "    print(\"node\", node.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "node 0.33848023090543683\n",
    "node T-dot > G-dot\n",
    "node {'author': 'George', 'fruit': 'grape', 'city': 'Toronto'}\n",
    "node 0.13562373847315362\n",
    "node りんごとは\n",
    "node {'author': 'Tanaka', 'fruit': 'apple', 'city': 'Tokyo'}\n",
    "\n",
    "\n",
    "鸣谢：本节内容参考了Llama-index官方文档"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.10.10",
   "language": "python",
   "name": "python-3.10.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
